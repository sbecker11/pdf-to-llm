{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calling ~/.zshenv\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: pandas in ./venv/lib/python3.11/site-packages (2.2.1)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in ./venv/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./venv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./venv/lib/python3.11/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in ./venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "calling ~/.zshenv\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: scikit-learn in ./venv/lib/python3.11/site-packages (1.4.1.post1)\n",
      "Requirement already satisfied: numpy<2.0,>=1.19.5 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./venv/lib/python3.11/site-packages (from scikit-learn) (3.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "calling ~/.zshenv\n",
      "Looking in indexes: https://pypi.org/simple/\n",
      "Requirement already satisfied: PyPDF2 in ./venv/lib/python3.11/site-packages (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas\n",
    "%pip install scikit-learn\n",
    "%pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 10 out of 10 : Getting Started with Apache Hadoop.pdf...                                                             "
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from helper import extract_text_from_pdf, clean_text\n",
    "\n",
    "# Step 1: Read and clean PDF documents\n",
    "pdf_folder = \"./Books\"\n",
    "pdf_files = [file for file in os.listdir(pdf_folder) if file.endswith('.pdf')]\n",
    "\n",
    "corpus = []\n",
    "i = 1;\n",
    "N = 10\n",
    "pdf_files = pdf_files[0:N]\n",
    "for file in pdf_files:\n",
    "    print('\\r', end='')  # Return to the start of the line\n",
    "    print(' ' * 128, end='')  # Print spaces to clear the line\n",
    "    print('\\r', end='')  # Return to the start of the line again\n",
    "    print(f'processing {i} out of {N} : {file}...', end='', flush=True)\n",
    "    \n",
    "    i +=1\n",
    "    \n",
    "    try:\n",
    "        # Read PDF files and extract text (you may need to use a library like PyPDF2 or pdfplumber)\n",
    "        text = extract_text_from_pdf(os.path.join(pdf_folder, file))\n",
    "\n",
    "        # Perform any necessary text cleaning (e.g., removing special characters, stopwords, etc.)\n",
    "        cleaned_text = clean_text(text)\n",
    "        \n",
    "        corpus.append(cleaned_text)\n",
    "    except Exception as e:\n",
    "        print(f\"skipping {file} on Exception:{str(e)}\")\n",
    "    \n",
    "\n",
    "# Step 2: Convert text data into TF-IDF vectors\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "# Step 3: Compute cosine similarity between documents\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# Step 4: Save cosine similarity matrix to a file\n",
    "cosine_sim_df = pd.DataFrame(cosine_sim, columns=pdf_files, index=pdf_files)\n",
    "cosine_sim_df.to_csv(\"cosine_similarity_matrix.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
